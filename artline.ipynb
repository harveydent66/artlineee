{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "LlnXd6b0NQDG",
        "outputId": "c6d89fb1-a371-4c55-9216-02cabe7784d2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4c404822c0cf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda install -c fastchan fastai\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "from fastai.utils.mem import *\n",
        "from fastai.vision import open_image, load_learner, image, torch\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "from fastai.utils.mem import *\n",
        "from fastai.vision import open_image, load_learner, image, torch\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class FeatureLoss(nn.Module):\n",
        "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
        "        super().__init__()\n",
        "        self.m_feat = m_feat\n",
        "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "        self.wgts = layer_wgts\n",
        "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
        "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
        "\n",
        "    def make_features(self, x, clone=False):\n",
        "        self.m_feat(x)\n",
        "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "    \n",
        "    def forward(self, input, target):\n",
        "        out_feat = self.make_features(target, clone=True)\n",
        "        in_feat = self.make_features(input)\n",
        "        self.feat_losses = [base_loss(input,target)]\n",
        "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "        return sum(self.feat_losses)\n",
        "    \n",
        "    def __del__(self): self.hooks.remove()\n",
        "MODEL_URL = \"https://www.dropbox.com/s/starqc9qd2e1lg1/ArtLine_650.pkl?dl=1\"\n",
        "urllib.request.urlretrieve(MODEL_URL, \"ArtLine_650.pkl\")\n",
        "path = Path(\".\")\n",
        "learn=load_learner(path, 'ArtLine_650.pkl')\n",
        "\n",
        "url = 'https://images.pexels.com/photos/4380970/pexels-photo-4380970.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500' #@param {type:\"string\"}\n",
        "response = requests.get(url)\n",
        "img = PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "img_t = T.ToTensor()(img)\n",
        "img_fast = Image(img_t)\n",
        "show_image(img_fast, figsize=(8,8), interpolation='nearest');\n",
        "p,img_hr,b = learn.predict(img_fast)\n",
        "Image(img_hr).show(figsize=(8,8))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}